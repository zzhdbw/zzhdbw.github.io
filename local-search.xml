<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title></title>
    <link href="/2023/10/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84tokenizer/"/>
    <url>/2023/10/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84tokenizer/</url>
    
    <content type="html"><![CDATA[<h1 id="一，word（基于词）"><a href="#一，word（基于词）" class="headerlink" title="一，word（基于词）"></a>一，word（基于词）</h1><p>    中文分词可能需要借助分词工具，比如jieba，因为中文词之间没有空格等标记。英文分词只需要按照空格分就好，以下是中文和英文的例子：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs text">中文句子：我喜欢看电影和读书。<br>分词结果：我 | 喜欢 | 看 | 电影 | 和 | 读书。<br>英文句子：I enjoy watching movies and reading books.<br>分词结果：I | enjoy | watching | movies | and | reading | books.<br></code></pre></td></tr></table></figure><p>分词的优点有：</p><ul><li><strong>语义明确</strong>：以词为单位进行分词可以更好地保留每个词的语义，使得文本在后续处理中能够更准确地表达含义。</li><li><strong>上下文理解</strong>：以词为粒度进行分词有助于保留词语之间的关联性和上下文信息，从而在语义分析和理解时能够更好地捕捉句子的意图。</li></ul><p>缺点：</p><ul><li><strong>长尾效应和稀有词问题</strong>： 词表可能变得巨大，包含很多不常见的词汇，增加存储和训练成本，稀有词的训练数据有限，难以获得准确的表示。</li><li><strong>OOV（Out-of-Vocabulary）</strong>： 词粒度分词模型只能使用词表中的词来进行处理，无法处理词表之外的词汇，这就是所谓的OOV问题。</li><li><strong>形态关系和词缀</strong>： 无法捕捉同一词的不同形态，也无法有效学习词缀在不同词汇之间的共通性，限制了模型的语言理解能力，比如love和loves在word（词）粒度的词表中将会是两个词。</li></ul><h1 id="二，character-（基于字符）"><a href="#二，character-（基于字符）" class="headerlink" title="二，character （基于字符）"></a>二，character （基于字符）</h1><p>    以字符为单位进行分割，比较适合中文（6000多个常见字），但是对于英文来说，基本字符只有26个字母，分割后难以蕴含有效信息。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">中文句子：我喜欢看电影和读书。<br>分词结果：我 | 喜 | 欢 | 看 | 电 | 影 | 和 | 读 | 书 | 。<br><br>英文句子：I enjoy watching movies and reading books.<br>分词结果：I |   | e | n | j | o | y |   | w | a | t | c | h | i | n | g |   | m | o | v | i | e | s |   | a | n | d |   | r | e | a | d | i | n | g |   | b | o | o | k | s | .<br></code></pre></td></tr></table></figure><p>char（字符）粒度的优点有：</p><ul><li><strong>统一处理方式</strong>：字符粒度分词方法适用于不同语言，无需针对每种语言设计不同的分词规则或工具，具有通用性。</li><li><strong>解决OOV问题</strong>：由于字符粒度分词可以处理任何字符，无需维护词表，因此可以很好地处理一些新创词汇、专有名词等问题。</li></ul><p>缺点：</p><ul><li><strong>语义信息任务中效果较差。</strong></li><li><strong>处理效率低</strong>：由于文本被拆分为字符，处理的粒度较小，增加后续处理的计算成本和时间。</li></ul><h1 id="三，subword-（基于子词）"><a href="#三，subword-（基于子词）" class="headerlink" title="三，subword （基于子词）"></a>三，subword （基于子词）</h1><h2 id="1，WordPiece"><a href="#1，WordPiece" class="headerlink" title="1，WordPiece"></a>1，WordPiece</h2><p>    WordPiece核心思想是将单词拆分成多个前缀符号（比如BERT中的##）最小单元，再通过子词合并规则将最小单元进行合并为子词级别。例如对于单词”word”，拆分如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">w ##o ##r ##d<br></code></pre></td></tr></table></figure><p>    然后通过合并规则进行合并，从而循环迭代构建出一个词表，以下是核心步骤：</p><ol><li>计算初始词表：通过训练语料获得或者最初的英文中26个字母加上各种符号以及常见中文字符，这些作为初始词表。</li><li>计算合并分数：对训练语料拆分的多个子词单元通过合拼规则计算合并分数(互信息，即共现概率得分)。</li><li>合并分数最高的子词对：选择分数最高的子词对，将它们合并成一个新的子词单元，并更新词表。</li><li>重复合并步骤：不断重复步骤 2 和步骤 3，直到达到预定的词表大小、合并次数，或者直到不再有有意义的合并（即，进一步合并不会显著提高词表的效益）。</li><li>分词：使用最终得到的词汇表对文本进行分词。</li></ol><p>    缺点：<strong>无法解决oov问题</strong></p><h2 id="2，Byte-Pair-Encoding-BPE"><a href="#2，Byte-Pair-Encoding-BPE" class="headerlink" title="2，Byte-Pair Encoding (BPE)"></a>2，Byte-Pair Encoding (BPE)</h2><p>    Byte-Pair Encoding (BPE)核心思想是逐步合并出现频率最高的子词对而不是像Wordpiece计算合并分数，从而构建出一个词汇表，以下是核心步骤：</p><ol><li>计算初始词表：通过训练语料获得或者最初的英文中26个字母加上各种符号以及常见中文字符，这些作为初始词表。</li><li>构建频率统计：统计所有子词单元对（两个连续的子词）在文本中的出现频率。</li><li>合并频率最高的子词对：选择出现频率最高的子词对，将它们合并成一个新的子词单元，并更新词汇表。</li><li>重复合并步骤：不断重复步骤 2 和步骤 3，直到达到预定的词汇表大小、合并次数，或者直到不再有有意义的合并（即，进一步合并不会显著提高词汇表的效益）。</li><li>分词：使用最终得到的词汇表对文本进行分词。</li></ol><p>    缺点：<strong>无法解决oov问题</strong></p><h2 id="3，Byte-level-BPE-BBPE"><a href="#3，Byte-level-BPE-BBPE" class="headerlink" title="3，Byte-level BPE(BBPE)"></a>3，Byte-level BPE(BBPE)</h2><p>    byte级别的分词方案，原理和BPE一致</p><p>    Byte-level BPE(BBPE)和Byte-Pair Encoding (BPE)区别就是BPE是最小词汇是字符级别，而BBPE是字节级别的，通过UTF-8的编码方式这一个字节的256的范围，理论上可以表示这个世界上的所有字符。</p><h2 id="3，unigram"><a href="#3，unigram" class="headerlink" title="3，unigram"></a>3，unigram</h2><h2 id="4，bytepiece"><a href="#4，bytepiece" class="headerlink" title="4，bytepiece"></a>4，bytepiece</h2><p>    苏剑林发布的</p><h1 id="四，总结"><a href="#四，总结" class="headerlink" title="四，总结"></a>四，总结</h1><h1 id="五，实践"><a href="#五，实践" class="headerlink" title="五，实践"></a>五，实践</h1><p>    SentencePiece工具</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
